{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525634ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title: Model Selection and Performance Evaluation for Prediction of Perinatal Asphyxia\n",
    "# Author: Cephas Ekow Biney\n",
    "# Institution: Kwame Nkrumah University of Science and Technology (KNUST)\n",
    "# Date: 6th October, 2025.\n",
    "# Description: \n",
    "#               This notebook shows the models that were used and the evaluation of their\n",
    "#               performance on the cleaned neonatal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77702f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the top predictors for the model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba06dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models Selected\n",
    "models = {\n",
    "    'lr': LogisticRegression(),\n",
    "    'svm': SVC(probability=True),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'xgb': XGBClassifier()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined Parameters\n",
    "param_grids = {\n",
    "    'lr': {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'solver': ['lbfgs', 'saga', 'liblinear'],\n",
    "        'max_iter': [100, 200, 500, 1000]\n",
    "    },\n",
    "\n",
    "    'svm': {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1, 1.0, 10.0],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'degree': [1, 2, 3, 4],\n",
    "        'coef0': [0, 0.1, 0.5, 1]\n",
    "    },\n",
    "\n",
    "    'dt': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 5, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 8, 10],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "\n",
    "    'rf': {\n",
    "        'n_estimators': [50, 100, 200, 300, 500],\n",
    "        'criterion':['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30, 40],\n",
    "        'min_samples_split': [2, 5, 8, 10]\n",
    "    },\n",
    "\n",
    "    'xgb': {\n",
    "        'n_estimators': [50, 100, 200, 300, 500],\n",
    "        'max_depth': [3, 6, 9],  # Removed None\n",
    "        'learning_rate': [0.01, 0.1, 1.0, 10.0]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV and RandomizedSearchCV\n",
    "# Randomized Search\n",
    "def random_search(model, param_distributions, X_train, y_train, n_iter=10):\n",
    "    \n",
    "    random_search_cv = RandomizedSearchCV(model, param_distributions, n_iter=n_iter, random_state=42, cv=10, n_jobs=-1)\n",
    "    random_search_cv.fit(X_train, y_train)\n",
    "    return random_search_cv.best_estimator_\n",
    "\n",
    "# Grid Search\n",
    "def grid_search(model, param_grids, X_train, y_train):\n",
    "\n",
    "    grid_search_cv = GridSearchCV(model, param_grids, cv=10, n_jobs=-1)\n",
    "    grid_search_cv.fit(X_train, y_train)\n",
    "    return grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    \n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Evaluation\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 'N/A'\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc if roc_auc != 'N/A' else 'Not applicable'}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    plot_confusion_matrix(y_test, y_pred, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296452bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result\n",
    "for model_name in models:\n",
    "    print(f\"Performing Random Search on {model_name.upper()}...\")\n",
    "    best_model_random = random_search(models[model_name], param_grids[model_name], X_train, y_train)\n",
    "    \n",
    "    print(f\"Evaluating {model_name.upper()} after Random Search...\")\n",
    "    evaluate_model(best_model_random, X_test, y_test, model_name.upper())\n",
    "    \n",
    "    print(f\"Performing Grid Search on {model_name.upper()}...\")\n",
    "    best_model_grid = grid_search(models[model_name], param_grids[model_name], X_train, y_train)\n",
    "    \n",
    "    print(f\"Evaluating {model_name.upper()} after Grid Search...\")\n",
    "    evaluate_model(best_model_grid, X_test, y_test, model_name.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21835e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the AUROC Curves\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name in models:\n",
    "    # Random Search Evaluation\n",
    "    print(f\"Performing Random Search on {model_name.upper()}...\")\n",
    "    best_model_random = random_search(models[model_name], param_grids[model_name], X_train, y_train)\n",
    "\n",
    "    print(f\"Evaluating {model_name.upper()} after Random Search...\")\n",
    "    y_proba_random = best_model_random.predict_proba(X_test)[:, 1] if hasattr(best_model_random, 'predict_proba') else None\n",
    "    if y_proba_random is not None:\n",
    "        fpr_random, tpr_random, _ = roc_curve(y_test, y_proba_random)\n",
    "        auc_random = auc(fpr_random, tpr_random)\n",
    "        plt.plot(fpr_random, tpr_random, label=f\"{model_name.upper()} - AUC: {auc_random:.2f}\")\n",
    "\n",
    "    # Grid Search Evaluation\n",
    "    print(f\"Performing Grid Search on {model_name.upper()}...\")\n",
    "    best_model_grid = grid_search(models[model_name], param_grids[model_name], X_train, y_train)\n",
    "\n",
    "    print(f\"Evaluating {model_name.upper()} after Grid Search...\")\n",
    "    y_proba_grid = best_model_grid.predict_proba(X_test)[:, 1] if hasattr(best_model_grid, 'predict_proba') else None\n",
    "    if y_proba_grid is not None:\n",
    "        fpr_grid, tpr_grid, _ = roc_curve(y_test, y_proba_grid)\n",
    "        auc_grid = auc(fpr_grid, tpr_grid)\n",
    "        plt.plot(fpr_grid, tpr_grid, label=f\"{model_name.upper()} - AUC: {auc_grid:.2f}\")\n",
    "        \n",
    "\n",
    "# Finalizing the AUROC Plot\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"AUROC Curve for All Models\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb69e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compbio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
